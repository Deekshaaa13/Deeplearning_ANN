{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv('Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:,3:13]\n",
    "y = dataset.iloc[:, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geography=pd.get_dummies(X[\"Geography\"],drop_first=True)\n",
    "gender=pd.get_dummies(X['Gender'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.concat([X,geography,gender],axis=1)\n",
    "X=X.drop(['Geography','Gender'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Germany  Spain  Male  \n",
       "0                  1        101348.88        0      0     0  \n",
       "1                  1        112542.58        0      1     0  \n",
       "2                  0        113931.57        0      0     0  \n",
       "3                  0         93826.63        0      0     0  \n",
       "4                  1         79084.10        0      1     0  \n",
       "...              ...              ...      ...    ...   ...  \n",
       "9995               0         96270.64        0      0     1  \n",
       "9996               1        101699.77        0      0     1  \n",
       "9997               1         42085.58        0      0     0  \n",
       "9998               0         92888.52        1      0     1  \n",
       "9999               0         38190.78        0      0     0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential ##This sequential library creates the model and this creates the models in ANN, CNN and RNN.\n",
    "from keras.layers import Dense ##Dense is used to create any hidden layers in the neural network\n",
    "from keras.layers import LeakyReLU,PReLU,ELU ##These are the activation functions\n",
    "from keras.layers import Dropout ##Dropout is used to solve the overfitting problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising ANN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the keras is downloaded using tensorflow as the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=6,kernel_initializer= 'he_uniform',activation='relu',input_dim=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dropout(0.3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This means that the model will have 11 input features and 6 hidden neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dropout(0.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next layer will again have 6 hidden neurons. So this hidden layer has 6 input features plus 6 output features. We use RELU activation function because RELU works well for he_uniform weight initializer. And also all the hidden layers should have either RELU or Leaky RELU activation function because it prevents vanishing gradient problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This means that the output is a binary classifier and the activation function is sigmoid. So if the value is greater  than 0.5 it will be 1 else it is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='Adamax',loss='binary_crossentropy',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The optimizer here reduces the loss function and we use binary_crossentropy because we have just 2 classes output. If we have many classes we use categorical_crossentropy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5993 - accuracy: 0.7886 - val_loss: 0.5315 - val_accuracy: 0.7955\n",
      "Epoch 2/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5385 - accuracy: 0.7960 - val_loss: 0.5128 - val_accuracy: 0.7955\n",
      "Epoch 3/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5270 - accuracy: 0.7962 - val_loss: 0.5103 - val_accuracy: 0.7955\n",
      "Epoch 4/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5278 - accuracy: 0.7962 - val_loss: 0.5102 - val_accuracy: 0.7955\n",
      "Epoch 5/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5153 - accuracy: 0.7962 - val_loss: 0.5094 - val_accuracy: 0.7955\n",
      "Epoch 6/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5167 - accuracy: 0.7962 - val_loss: 0.5094 - val_accuracy: 0.7955\n",
      "Epoch 7/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5151 - accuracy: 0.7962 - val_loss: 0.5095 - val_accuracy: 0.7955\n",
      "Epoch 8/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5148 - accuracy: 0.7962 - val_loss: 0.5086 - val_accuracy: 0.7955\n",
      "Epoch 9/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5147 - accuracy: 0.7962 - val_loss: 0.5082 - val_accuracy: 0.7955\n",
      "Epoch 10/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5109 - accuracy: 0.7962 - val_loss: 0.5076 - val_accuracy: 0.7955\n",
      "Epoch 11/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5111 - accuracy: 0.7962 - val_loss: 0.5075 - val_accuracy: 0.7955\n",
      "Epoch 12/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5120 - accuracy: 0.7962 - val_loss: 0.5073 - val_accuracy: 0.7955\n",
      "Epoch 13/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5103 - accuracy: 0.7962 - val_loss: 0.5072 - val_accuracy: 0.7955\n",
      "Epoch 14/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5103 - accuracy: 0.7962 - val_loss: 0.5069 - val_accuracy: 0.7955\n",
      "Epoch 15/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5135 - accuracy: 0.7962 - val_loss: 0.5072 - val_accuracy: 0.7955\n",
      "Epoch 16/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5078 - accuracy: 0.7962 - val_loss: 0.5069 - val_accuracy: 0.7955\n",
      "Epoch 17/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5083 - accuracy: 0.7962 - val_loss: 0.5067 - val_accuracy: 0.7955\n",
      "Epoch 18/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5113 - accuracy: 0.7962 - val_loss: 0.5069 - val_accuracy: 0.7955\n",
      "Epoch 19/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5100 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 20/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.5099 - accuracy: 0.7962 - val_loss: 0.5068 - val_accuracy: 0.7955\n",
      "Epoch 21/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5088 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 22/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5101 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 23/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.5087 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 24/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5057 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 25/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5082 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 26/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5093 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 27/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5086 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 28/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5067 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 29/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5079 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 30/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5083 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 31/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5070 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 32/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5068 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 33/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5067 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 34/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5073 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 35/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5065 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 36/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 37/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5082 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 38/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 39/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 40/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 41/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 42/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5064 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 43/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 44/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 45/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 46/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 47/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 48/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5067 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 49/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 50/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 51/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5050 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 52/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 53/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 54/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 55/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 56/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 57/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5064 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 58/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 59/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5066 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 60/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5063 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 61/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 62/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 63/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 64/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 65/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 66/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5065 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 67/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5062 - accuracy: 0.7962 - val_loss: 0.5066 - val_accuracy: 0.7955\n",
      "Epoch 68/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 69/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 70/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 71/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 72/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 73/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 74/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5061 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 75/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 76/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 77/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 78/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 79/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5057 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 80/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5054 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 81/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 82/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 83/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 84/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 85/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 86/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 87/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5055 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 88/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 89/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 90/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 91/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5054 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 92/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5060 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 93/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5059 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 94/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5055 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 95/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 96/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5057 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 97/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 98/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5057 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 99/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5056 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n",
      "Epoch 100/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.7962 - val_loss: 0.5065 - val_accuracy: 0.7955\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.33,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So we see here that just by using the right initializer we are able to get good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [False],\n",
       "       [False]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=classifier.predict(X_test) ##Predicting the test set results.\n",
    "y_pred=(y_pred>0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7975"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From this we see that the training accuracy(validation accuracy is almost same as the test accuracy.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also work with different permutations and combinations of the hidden layers that is we can change the number of units in the hidden layers and check if it increases the accuracy. Also try using he_normal as it works well with the RELU activation function. Also try using dropout function to reduce overfitting problems. Even if the accuracy reduces by using dropout it doesnt mean that its a bad thing because previously without dropout it might have led to overfitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
